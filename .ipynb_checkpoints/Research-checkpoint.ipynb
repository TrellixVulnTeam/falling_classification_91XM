{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    def fit(self, dataset):\n",
    "        self.dataset = dataset.copy()\n",
    "\n",
    "    # apply regex\n",
    "    def get_title(self, name):\n",
    "        pattern = ' ([A-Za-z]+)\\.'\n",
    "        title_search = re.search(pattern, name)\n",
    "        # If the title exists, extract and return it.\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "\n",
    "    def load_data(self):\n",
    "        \n",
    "        #outliers\n",
    "#         df = self.dataset.drop(\"FALLING\",axis=1)\n",
    "#         Q1 = self.dataset.quantile(0.25)\n",
    "#         Q3 = self.dataset.quantile(0.75)\n",
    "#         IQR = Q3 - Q1\n",
    "#         self.dataset = self.dataset[~((self.dataset.loc[:, self.dataset.columns != 'FALLING'] < (Q1 - 1.5 * IQR)) |\n",
    "#                                       (self.dataset.loc[:, self.dataset.columns != 'FALLING'] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "        \n",
    "        #drop columns\n",
    "        self.dataset = self.dataset.drop(['SL','EEG'], axis=1)\n",
    "\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('data/train.csv')\n",
    "db_test = pd.read_csv('data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>BP</th>\n",
       "      <th>HR</th>\n",
       "      <th>CIRCULATION</th>\n",
       "      <th>FALLING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9582.21</td>\n",
       "      <td>92</td>\n",
       "      <td>136</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5717.83</td>\n",
       "      <td>24</td>\n",
       "      <td>102</td>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11899.00</td>\n",
       "      <td>25</td>\n",
       "      <td>223</td>\n",
       "      <td>1809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20476.40</td>\n",
       "      <td>358</td>\n",
       "      <td>517</td>\n",
       "      <td>11883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7463.33</td>\n",
       "      <td>35</td>\n",
       "      <td>131</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4649.90</td>\n",
       "      <td>28</td>\n",
       "      <td>71</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12181.70</td>\n",
       "      <td>21</td>\n",
       "      <td>249</td>\n",
       "      <td>3630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4704.48</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4258.17</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3954.47</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME   BP   HR  CIRCULATION  FALLING\n",
       "0   9582.21   92  136          619        1\n",
       "1   5717.83   24  102          764        0\n",
       "2  11899.00   25  223         1809        0\n",
       "3  20476.40  358  517        11883        0\n",
       "4   7463.33   35  131          271        0\n",
       "5   4649.90   28   71          249        1\n",
       "6  12181.70   21  249         3630        0\n",
       "7   4704.48   34   71          249        1\n",
       "8   4258.17    5   63          166        1\n",
       "9   3954.47   42   52          133        0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.fit(db)\n",
    "df = dl.load_data()\n",
    "dl.fit(db_test)\n",
    "df_test = dl.load_data()\n",
    "df_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df.drop(['FALLING'], axis=1), df['FALLING']\n",
    "X_test, y_test = df_test.drop(['FALLING'], axis=1), df_test['FALLING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1885    1]\n",
      " [ 572    0]]\n",
      "Accuracy Score : 0.77\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1886\n",
      "           1       0.00      0.00      0.00       572\n",
      "\n",
      "    accuracy                           0.77      2458\n",
      "   macro avg       0.38      0.50      0.43      2458\n",
      "weighted avg       0.59      0.77      0.67      2458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_predict = lr.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and accuracy score\n",
    "lr_conf_matrix = confusion_matrix(y_test, lr_predict)\n",
    "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
    "lr_class_report = classification_report(y_test, lr_predict) \n",
    "print(lr_conf_matrix)\n",
    "print('Accuracy Score :', '%.2f' %lr_acc_score)\n",
    "print('Classification Report :')\n",
    "print(lr_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1641  245]\n",
      " [ 240  332]]\n",
      "Accuracy Score : 0.80\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      1886\n",
      "           1       0.58      0.58      0.58       572\n",
      "\n",
      "    accuracy                           0.80      2458\n",
      "   macro avg       0.72      0.73      0.72      2458\n",
      "weighted avg       0.80      0.80      0.80      2458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "dt_predict = dt.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and accuracy score\n",
    "dt_conf_matrix = confusion_matrix(y_test, dt_predict)\n",
    "dt_acc_score = accuracy_score(y_test, dt_predict)\n",
    "dt_class_report = classification_report(y_test, dt_predict) \n",
    "print(dt_conf_matrix)\n",
    "print('Accuracy Score :', '%.2f' %dt_acc_score)\n",
    "print('Classification Report :')\n",
    "print(dt_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1688  198]\n",
      " [ 274  298]]\n",
      "Accuracy Score : 0.81\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1886\n",
      "           1       0.60      0.52      0.56       572\n",
      "\n",
      "    accuracy                           0.81      2458\n",
      "   macro avg       0.73      0.71      0.72      2458\n",
      "weighted avg       0.80      0.81      0.80      2458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn_predict = knn.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and accuracy score\n",
    "knn_conf_matrix = confusion_matrix(y_test, knn_predict)\n",
    "knn_acc_score = accuracy_score(y_test, knn_predict)\n",
    "knn_class_report = classification_report(y_test, knn_predict) \n",
    "print(knn_conf_matrix)\n",
    "print('Accuracy Score :', '%.2f' %knn_acc_score)\n",
    "print('Classification Report :')\n",
    "print(knn_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1886    0]\n",
      " [ 572    0]]\n",
      "Accuracy Score : 0.77\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1886\n",
      "           1       0.00      0.00      0.00       572\n",
      "\n",
      "    accuracy                           0.77      2458\n",
      "   macro avg       0.38      0.50      0.43      2458\n",
      "weighted avg       0.59      0.77      0.67      2458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\my_ro\\app\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\my_ro\\app\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\my_ro\\app\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "nb_predict = nb.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and accuracy score\n",
    "nb_conf_matrix = confusion_matrix(y_test, nb_predict)\n",
    "nb_acc_score = accuracy_score(y_test, nb_predict)\n",
    "nb_class_report = classification_report(y_test, nb_predict) \n",
    "print(nb_conf_matrix)\n",
    "print('Accuracy Score :', '%.2f' %nb_acc_score)\n",
    "print('Classification Report :')\n",
    "print(nb_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1739  147]\n",
      " [ 231  341]]\n",
      "Accuracy Score : 0.85\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      1886\n",
      "           1       0.70      0.60      0.64       572\n",
      "\n",
      "    accuracy                           0.85      2458\n",
      "   macro avg       0.79      0.76      0.77      2458\n",
      "weighted avg       0.84      0.85      0.84      2458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "rf_predict = rf.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and accuracy score\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_acc_score = accuracy_score(y_test, rf_predict)\n",
    "rf_class_report = classification_report(y_test, rf_predict)\n",
    "print(rf_conf_matrix)\n",
    "print('Accuracy Score :','%.2f' %rf_acc_score)\n",
    "print('Classification Report :')\n",
    "print(rf_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1886    0]\n",
      " [ 572    0]]\n",
      "Accuracy Score : 0.77\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1886\n",
      "           1       0.00      0.00      0.00       572\n",
      "\n",
      "    accuracy                           0.77      2458\n",
      "   macro avg       0.38      0.50      0.43      2458\n",
      "weighted avg       0.59      0.77      0.67      2458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\my_ro\\app\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\my_ro\\app\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\my_ro\\app\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "svc_predict = svc.predict(X_test)\n",
    "\n",
    "# Print confusion matrix and accuracy score\n",
    "svc_conf_matrix = confusion_matrix(y_test, svc_predict)\n",
    "svc_acc_score = accuracy_score(y_test, svc_predict)\n",
    "svc_class_report = classification_report(y_test, svc_predict)\n",
    "print(svc_conf_matrix)\n",
    "print('Accuracy Score :','%.2f' %svc_acc_score)\n",
    "print('Classification Report :')\n",
    "print(svc_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from utils.dataloader import DataLoader \n",
    "from settings.constants import TRAIN_CSV\n",
    "\n",
    "\n",
    "with open('settings/specifications.json') as f:\n",
    "    specifications = json.load(f)\n",
    "\n",
    "raw_train = pd.read_csv(TRAIN_CSV)\n",
    "# x_columns = specifications['description']['X']\n",
    "# y_column = specifications['description']['y']\n",
    "\n",
    "# x_raw = raw_train[x_columns]\n",
    "\n",
    "loader = DataLoader()\n",
    "loader.fit(raw_train)\n",
    "new = loader.load_data()\n",
    "X = new.drop('FALLING',axis = 1)\n",
    "y = new.FALLING\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "with open('models/RFC.pickle', 'wb')as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
